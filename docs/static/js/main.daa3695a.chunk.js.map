{"version":3,"sources":["App.js","index.js"],"names":["machine","initial","states","on","next","startWebcam","loadModel","identify","complete","showImage","showResults","classList","1","name","id","App","useState","model","setModel","modelURL","webcam","setWebcam","showWebcam","setShowWebcam","modelReady","setModelReady","videoRef","useRef","canvasRef","useReducer","state","event","a","console","log","loadGraphModel","navigator","mediaDevices","getUserMedia","video","enumerateDevices","devices","webcamConfig","resizeWidth","resizeHeight","centerCrop","facingMode","tf","current","renderPredictions","predictions","ctx","getContext","clearRect","canvas","width","height","font","textBaseline","classes","arraySync","detections","scores","threshold","boxes","classesDir","detectionObjects","document","getElementById","forEach","score","i","bbox","minY","minX","maxY","maxX","classNum","label","push","class","toFixed","buildDetectedObjects","item","x","y","strokeStyle","lineWidth","strokeRect","fillStyle","textWidth","measureText","textHeight","parseInt","fillRect","fillText","detect","capture","img","tensor","reshape","toInt","expandDims","executeAsync","useEffect","timeout","setInterval","clearInterval","onClick","autoPlay","playsInline","muted","style","objectFit","ref","className","href","ReactDOM","render","StrictMode"],"mappings":"iZAOMA,EAAU,CACdC,QAAS,UACTC,OAAQ,CACND,QAAS,CAAEE,GAAI,CAAEC,KAAM,gBACvBC,YAAa,CAACF,GAAI,CAAEC,KAAM,cAC1BE,UAAW,CAAEH,GAAI,CAAEC,KAAM,aACzBG,SAAU,CAAEJ,GAAI,CAAEC,KAAM,aACxBI,SAAU,CAAEL,GAAI,CAAEC,KAAM,YAAcK,WAAW,EAAMC,aAAa,KAKpEC,EAAY,CACdC,EAAG,CACCC,KAAM,QACNC,GAAI,IAoOKC,MA9Nf,WAAgB,IAAD,EACiBC,mBAAS,IAD1B,gCAEaA,mBAAS,OAFtB,mBAENC,EAFM,KAECC,EAFD,OAGmBF,mBAAS,2CAH5B,mBAGNG,EAHM,aAIeH,mBAAS,OAJxB,mBAINI,EAJM,KAIEC,EAJF,OAKuBL,oBAAS,GALhC,mBAKNM,EALM,KAKMC,EALN,OAMiBP,mBAAS,MAN1B,gCAOuBA,oBAAS,IAPhC,mBAONQ,EAPM,KAOMC,EAPN,OAQyBT,oBAAS,GARlC,mBASPU,GATO,UASIC,oBACXC,EAAYD,mBAVL,EAegBE,sBAFb,SAACC,EAAOC,GAAR,OACd/B,EAAQE,OAAO4B,GAAO3B,GAAG4B,IAAU/B,EAAQC,UACID,EAAQC,SAf5C,mBAkBPK,GAlBO,UAkBE,uCAAG,4BAAA0B,EAAA,6DAChBC,QAAQC,IAAI,WAAaf,EAAW,OADpB,SAGIgB,YAAehB,GAHnB,OAGVF,EAHU,OAKhBgB,QAAQC,IAAI,6BACZhB,EAASD,GACTQ,GAAc,GAPE,2CAAH,sDAWTpB,EAAW,uCAAG,gCAAA2B,EAAA,6DAClBT,GAAc,GACV,iBAAkBa,WAAa,iBAAkBA,UAAUC,cAC7DJ,QAAQC,IAAI,gCAEdE,UAAUC,aAAaC,aAAa,CAACC,OAAO,IAL1B,SAOIH,UAAUC,aAAaG,mBAP3B,cAOZC,EAPY,OAQlBR,QAAQC,IAAIO,GACNC,EAAe,CAAEC,YAAa,IAAKC,aAAc,IAAKC,YAAY,EAAMC,WAAY,eATxE,UAUGC,IAAQ3B,OAAOM,EAASsB,QAAQN,GAVnC,QAUZtB,EAVY,OAWlBC,EAAUD,GACLI,GACHlB,IAbgB,4CAAH,qDA+CX2C,EAAoB,SAAAC,GACxB,IAAMC,EAAMvB,EAAUoB,QAAQI,WAAW,MACzCD,EAAIE,UAAU,EAAG,EAAGF,EAAIG,OAAOC,MAAOJ,EAAIG,OAAOE,QAGjD,IAAMC,EAAO,kBACbN,EAAIM,KAAOA,EACXN,EAAIO,aAAe,MAYnB,IAAOC,EAAUT,EAAY,GAAGU,YAc1BC,EA/DqB,SAACC,EAAQC,EAAWC,EAAOL,EAASM,GAC/D,IAAMC,EAAmB,GA2BzB,OA1BkBC,SAASC,eAAe,UAE1CN,EAAO,GAAGO,SAAQ,SAACC,EAAOC,GACxB,GAAID,EAAQP,EAAW,CACrB,IAAMS,EAAO,GACPC,EAAwB,IAAjBT,EAAM,GAAGO,GAAG,GACnBG,EAAwB,IAAjBV,EAAM,GAAGO,GAAG,GACnBI,EAAwB,IAAjBX,EAAM,GAAGO,GAAG,GACnBK,EAAwB,IAAjBZ,EAAM,GAAGO,GAAG,GACzBC,EAAK,GAAKE,EACVF,EAAK,GAAKC,EACVD,EAAK,GAAKI,EAAOF,EACjBF,EAAK,GAAKG,EAAOF,EACjB,IAAMI,EAAWlB,EAAQ,GAAGY,GACxBO,EAAQ,QACRb,EAAWY,KACbC,EAAQb,EAAWY,GAAUhE,MAE/BqD,EAAiBa,KAAK,CACpBC,MAAOH,EACPC,MAAOA,EACPR,MAAOA,EAAMW,QAAQ,GACrBT,KAAMA,QAILN,EAmCYgB,CAbJhC,EAAY,GAAGU,YAnGhB,GAoGAV,EAAY,GAAGU,YAapBD,EAAShD,GAElBkD,EAAWQ,SAAQ,SAAAc,GACjB,IAAMC,EAAID,EAAI,KAAS,GACjBE,EAAIF,EAAI,KAAS,GACjB5B,EAAQ4B,EAAI,KAAS,GACrB3B,EAAS2B,EAAI,KAAS,GAG5BhC,EAAImC,YAAc,UAClBnC,EAAIoC,UAAY,EAChBpC,EAAIqC,WAAWJ,EAAGC,EAAG9B,EAAOC,GAG5BL,EAAIsC,UAAY,UAChB,IAAMC,EAAYvC,EAAIwC,YAAYR,EAAI,MAAY,KAAO,IAAMA,EAAI,OAAWF,QAAQ,GAAK,KAAK1B,MAC1FqC,EAAaC,SAASpC,EAAM,IAClCN,EAAI2C,SAASV,EAAGC,EAAGK,EAAY,EAAGE,EAAa,MAGjD/B,EAAWQ,SAAQ,SAAAc,GACjB,IAAMC,EAAID,EAAI,KAAS,GACjBE,EAAIF,EAAI,KAAS,GAGvBhC,EAAIsC,UAAY,UAChBtC,EAAI4C,SAASZ,EAAI,MAAY,KAAO,IAAIA,EAAI,OAAWF,QAAQ,GAAK,IAAKG,EAAGC,OAI1EW,EAAM,uCAAG,gCAAAhE,EAAA,sEACKZ,EAAO6E,UADZ,cACPC,EADO,OAETC,EAASD,EAAIE,QAAQ,CAAC,EAAE,IAAK,IAAI,IAAIC,QAG5BtD,IAAU,OACNmD,EAAII,aAAaF,QAAQ,CAAC,EAAG,IAAK,IAAK,IACvCrD,IAAcmD,EAAIG,SAASD,QAAQ,EAAE,EAAG,IAAK,IAAK,IAPtD,SASanF,EAAMsF,aAAaJ,GAThC,OASPjD,EATO,OAUbD,EAAkBC,GAVL,4CAAH,qDA2CZ,OAfAsD,qBAAU,WACR,IAAMC,EAAUC,aAAY,WACtBlF,GAAcJ,GAChB4E,MAED,KACH,OAAO,WACLW,cAAcF,OAIlBD,qBAAU,WACRlG,MACC,CAACa,IAGF,gCACA,sBAAKL,GAAG,OAAR,UACM,gDACEQ,GACN,wBAAQsF,QAASvG,EAAjB,0BAICiB,GACA,sBAAKR,GAAG,YAAR,UACD,uBAAO+F,UAAQ,EAACC,aAAW,EAACC,OAAK,EAACjG,GAAG,SAASyC,MAAM,QAAQC,OAAO,QAAQwD,MAAO,CAACC,UAAU,SAAUC,IAAKxF,IAC5G,wBACIyF,UAAU,OACVD,IAAKtF,OAKR,qBAAKd,GAAG,aAAR,SAAqB,gKAEtB,qBAAKA,GAAG,YAAR,SACA,gCACE,+CACA,qIAAuG,mBAAGsG,KAAK,qCAAR,qBAAvG,cACD,yDACC,8BAAG,mBAAGA,KAAK,qCAAR,qBAAH,wUAGD,6DAA+B,mBAAGA,KAAK,wDAAR,uBAA/B,yFAAkM,mBAAGA,KAAK,6EAAR,kCAAlM,OAEC,sIC7ORC,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFpD,SAASC,eAAe,W","file":"static/js/main.daa3695a.chunk.js","sourcesContent":["import React, { useState, useRef, useEffect, useReducer } from \"react\";\nimport * as tf from '@tensorflow/tfjs';\nimport {loadGraphModel} from '@tensorflow/tfjs-converter';\nimport '@tensorflow/tfjs-backend-cpu';\nimport '@tensorflow/tfjs-backend-webgl';\nimport \"./App.css\";\n\nconst machine = {\n  initial: \"initial\",\n  states: {\n    initial: { on: { next: \"startWebcam\" } },\n    startWebcam: {on: { next: \"loadModel\"}},\n    loadModel: { on: { next: \"identify\" } },\n    identify: { on: { next: \"complete\" }},\n    complete: { on: { next: \"identify\" }, showImage: true, showResults: true }\n  }\n};\n\n\nlet classList = {\n  1: {\n      name: 'Plane',\n      id: 1,\n  }\n}\nconst threshold = 0.60;\n\n\nfunction App() {\n  const [results, setResults] = useState([]);\n  const [model, setModel] = useState(null);\n  const [modelURL, setModelURL] = useState('web_mobilenet_balanced_model/model.json');\n  const [webcam, setWebcam] = useState(null);\n  const [showWebcam, setShowWebcam] = useState(false);\n  const [objPred, setObjPred] = useState(null);\n  const [modelReady, setModelReady] = useState(false);\n  const [showResults, setShowResults] = useState(false);\n  const videoRef = useRef();\n  const canvasRef = useRef();\n\n \n  const reducer = (state, event) => \n    machine.states[state].on[event] || machine.initial;\n  const [appState, dispatch] = useReducer(reducer, machine.initial);\n  const next = () => dispatch(\"next\");\n\n  const loadModel = async () => {\n    console.log('Loading ' + modelURL + '...');\n  \n    const model = await loadGraphModel(modelURL);\n    \n    console.log('Successfully loaded model');\n    setModel(model);\n    setModelReady(true);\n  };\n\n  \n  const startWebcam = async () => {\n    setShowWebcam(true);\n    if ('mediaDevices' in navigator && 'getUserMedia' in navigator.mediaDevices) {\n      console.log(\"Let's get this party started\")\n    }\n    navigator.mediaDevices.getUserMedia({video: true})\n  \n    const devices = await navigator.mediaDevices.enumerateDevices();\n    console.log(devices);\n    const webcamConfig = { resizeWidth: 300, resizeHeight: 300, centerCrop: true, facingMode: 'environment'}\n    const webcam = await tf.data.webcam(videoRef.current,webcamConfig);\n    setWebcam(webcam);\n    if (!modelReady) {\n      loadModel();\n    }\n  };\n\n  const buildDetectedObjects = (scores, threshold, boxes, classes, classesDir) => {\n    const detectionObjects = []\n    var video_frame = document.getElementById('webcam');\n\n    scores[0].forEach((score, i) => {\n      if (score > threshold) {\n        const bbox = [];\n        const minY = boxes[0][i][0] * 300;//video_frame.offsetHeight;\n        const minX = boxes[0][i][1] * 300;//video_frame.offsetWidth;\n        const maxY = boxes[0][i][2] * 300;//video_frame.offsetHeight;\n        const maxX = boxes[0][i][3] * 300;//video_frame.offsetWidth;\n        bbox[0] = minX;\n        bbox[1] = minY;\n        bbox[2] = maxX - minX;\n        bbox[3] = maxY - minY;\n        const classNum = classes[0][i] \n        var label = \"Thing\";\n        if (classesDir[classNum]) {\n          label = classesDir[classNum].name\n        }\n        detectionObjects.push({\n          class: classNum,\n          label: label,\n          score: score.toFixed(4),\n          bbox: bbox\n        })\n      }\n    })\n    return detectionObjects\n  }\n  const renderPredictions = predictions => {\n    const ctx = canvasRef.current.getContext(\"2d\");\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n\n    // Font options.\n    const font = \"16px sans-serif\";\n    ctx.font = font;\n    ctx.textBaseline = \"top\";\n\n    //Getting predictions\n\n    /*\n    // MobileNet FPN\n    const  classes = predictions[2].arraySync() //7\n    const scores = predictions[4].arraySync()  //4\n    const boxes = predictions[3].arraySync()  //6\n*/\n\n    // MobileNet \n    const  classes = predictions[7].arraySync() //7\n    const scores = predictions[4].arraySync()  //4\n    const boxes = predictions[6].arraySync()  //6\n\n    /*const prediction0 = predictions[0].arraySync()\n    const prediction1 = predictions[1].arraySync()\n    const prediction2 = predictions[2].arraySync()\n    const prediction3 = predictions[3].arraySync()\n    const prediction4 = predictions[4].arraySync()\n    const prediction5 = predictions[5].arraySync()\n    const prediction6 = predictions[6].arraySync()\n    const prediction7 = predictions[7].arraySync()*/\n    \n    \n    const detections = buildDetectedObjects(scores, threshold,\n      boxes, classes, classList);\n\n    detections.forEach(item => {\n      const x = item['bbox'][0];\n      const y = item['bbox'][1];\n      const width = item['bbox'][2];\n      const height = item['bbox'][3];\n\n      // Draw the bounding box.\n      ctx.strokeStyle = \"#00FFFF\";\n      ctx.lineWidth = 4;\n      ctx.strokeRect(x, y, width, height);\n\n      // Draw the label background.\n      ctx.fillStyle = \"#00FFFF\";\n      const textWidth = ctx.measureText(item[\"label\"] + \" \" + (100 * item[\"score\"]).toFixed(2) + \"%\").width;\n      const textHeight = parseInt(font, 10); // base 10\n      ctx.fillRect(x, y, textWidth + 4, textHeight + 4);\n    });\n\n    detections.forEach(item => {\n      const x = item['bbox'][0];\n      const y = item['bbox'][1];\n\n      // Draw the text last to ensure it's on top.\n      ctx.fillStyle = \"#000000\";\n      ctx.fillText(item[\"label\"] + \" \" + (100*item[\"score\"]).toFixed(2) + \"%\", x, y);\n    });\n  };\n\n  const detect = async () => {\n    const img = await webcam.capture();\n    let tensor = img.reshape([1,300, 300,3]).toInt(); // change the image size\n\n\n    let offset = tf.scalar(127.5);\n    var  new_frame = img.expandDims().reshape([1, 300, 300, 3]);    \n    var test_frame = tf.expandDims(img.toInt()).reshape([-1, 300, 300, 3]);\n\n    const predictions = await model.executeAsync(tensor); \n    renderPredictions(predictions)\n  };\n\n  const reset = async () => {\n    setResults([]);\n    next();\n  };\n\n\n  const actionButton = {\n    initial: { action: startWebcam, text: \"Start\" },\n    startWebcam: { text: \"Starting Webcam...\" },\n    loadModel: { text: \"Loading Model...\" },\n    identify: { text: \"Identifying...\" },\n    complete: { action: reset, text: \"Reset\" }\n  };\n\n \n  useEffect(() => {\n    const timeout = setInterval(() => {\n      if (modelReady && webcam) {\n        detect();\n      }\n    }, 1000);\n    return () => {\n      clearInterval(timeout);  // this guarantees to run right before the next effect\n    }\n  });\n\n  useEffect(() => {\n    loadModel();\n  }, [modelURL]); // Only re-run the effect if count changes\n  \n  return (\n    <div>\n    <div id=\"main\">\n          <h1>Plane Spotter</h1>\n          {!showWebcam && (\n      <button onClick={startWebcam}>\n        Start Webcam\n      </button>\n      )}\n      {showWebcam && (\n       <div id=\"video-box\"  >  \n      <video autoPlay playsInline muted id=\"webcam\" width=\"300px\" height=\"300px\" style={{objectFit:\"cover\"}} ref={videoRef} />\n      <canvas\n          className=\"size\"\n          ref={canvasRef}\n        />\n      </div> \n      )}\n   \n       <div id=\"disclaimer\"><p>This model was trained on airplanes flying by at around 30,000 feet. It works best at identifying small plane silhouettes.</p></div>\n      </div>\n      <div id=\"explainer\">\n      <div>\n        <h2>What is this?</h2>\n        <p>An easy way to try out a custom Object Detection model that was trained using data collected by the <a href=\"https://github.com/IQTLabs/SkyScan\">SkyScan</a> system.</p>\n       <h2>How did you build this?</h2>\n        <p><a href=\"https://github.com/IQTLabs/SkyScan\">SkyScan</a> takes photos of airplanes as they fly by. It determines a planes location based\n        on the location signal they broadcast, using a standard called ADS-B. When a plane is nearby, it will point a camera at the airplane\n         zoom in and take a photo. This gave us a lot of data that was easy to label, so we used it to train a model.</p>\n       <p>We have created a series of <a href=\"https://github.com/IQTLabs/SkyScan/tree/main/ml-model\">notebooks</a> that make it easy to train your own Object Detections model using the TensorFlow 2.0 <a href=\"https://github.com/tensorflow/models/tree/master/research/object_detection\">Object Detection API</a>.</p>\n\n        <h3>Browser based apps are a great way to find out how well your model works in the real world!</h3>\n      </div>\n      </div>\n      </div>\n    \n  );\n}\n\nexport default App;","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n\n"],"sourceRoot":""}